# yaml-language-server: $schema=https://raw.githubusercontent.com/rendercv/rendercv/refs/tags/v2.4/schema.json
cv:
  name: John Doe
  headline:
  location: San Francisco, CA
  email: john.doe@email.com
  photo:
  phone:
  website: https://johndoe.ai/
  social_networks:
    - network: LinkedIn
      username: johndoe
    - network: GitHub
      username: johndoe
  sections:
    summary:
      - AI researcher and entrepreneur with a track record of publishing at top venues (NeurIPS, ICML, ICLR) and translating research into products used by millions.
      - Currently building [Nexus AI](https://nexusai.com), a VC-backed infrastructure company for efficient large model deployment.
    education:
      - date:
        start_date: 2018-09
        end_date: 2023-05
        location: Princeton, NJ
        summary:
        highlights:
          - 'Thesis: Efficient Neural Architecture Search for Resource-Constrained Deployment'
          - 'Advisor: Prof. Sanjeev Arora'
          - NSF Graduate Research Fellowship, Siebel Scholar (Class of 2022)
        institution: Princeton University
        area: Computer Science
        degree: PhD
      - date:
        start_date: 2014-09
        end_date: 2018-06
        location: Istanbul, Türkiye
        summary:
        highlights:
          - 'GPA: 3.97/4.00, Valedictorian'
          - Fulbright Scholarship recipient for graduate studies
        institution: Boğaziçi University
        area: Computer Engineering
        degree: BS
    experience:
      - date:
        start_date: 2023-06
        end_date: present
        location: San Francisco, CA
        summary:
        highlights:
          - Built foundation model infrastructure serving 2M+ monthly API requests with 99.97% uptime
          - Raised $18M Series A led by Sequoia Capital, with participation from a16z and Founders Fund
          - Scaled engineering team from 3 to 28 across ML research, platform, and applied AI divisions
          - Developed proprietary inference optimization reducing latency by 73% compared to baseline
        company: Nexus AI
        position: Co-Founder & CTO
      - date:
        start_date: 2022-05
        end_date: 2022-08
        location: Santa Clara, CA
        summary:
        highlights:
          - Designed sparse attention mechanism reducing transformer memory footprint by 4.2x
          - Co-authored paper accepted at NeurIPS 2022 (spotlight presentation, top 5% of submissions)
        company: NVIDIA Research
        position: Research Intern
      - date:
        start_date: 2021-05
        end_date: 2021-08
        location: London, UK
        summary:
        highlights:
          - Developed reinforcement learning algorithms for multi-agent coordination
          - Published research at top-tier venues with significant academic impact
            - ICML 2022 main conference paper, cited 340+ times within two years
            - NeurIPS 2022 workshop paper on emergent communication protocols
            - Invited journal extension in JMLR (2023)
        company: Google DeepMind
        position: Research Intern
      - date:
        start_date: 2020-05
        end_date: 2020-08
        location: Cupertino, CA
        summary:
        highlights:
          - Created on-device neural network compression pipeline deployed across 50M+ devices
          - Filed 2 patents on efficient model quantization techniques for edge inference
        company: Apple ML Research
        position: Research Intern
      - date:
        start_date: 2019-05
        end_date: 2019-08
        location: Redmond, WA
        summary:
        highlights:
          - Implemented novel self-supervised learning framework for low-resource language modeling
          - Research integrated into Azure Cognitive Services, reducing training data requirements by 60%
        company: Microsoft Research
        position: Research Intern
    projects:
      - date:
        start_date: 2023-01
        end_date: present
        location:
        summary: Open-source library for high-performance LLM inference kernels
        highlights:
          - Achieved 2.8x speedup over baseline attention implementations on A100 GPUs
          - Adopted by 3 major AI labs, 8,500+ GitHub stars, 200+ contributors
        name: '[FlashInfer](https://github.com/)'
      - date: '2021'
        start_date:
        end_date:
        location:
        summary: Automated neural network pruning toolkit with differentiable masks
        highlights:
          - Reduced model size by 90% with less than 1% accuracy degradation on ImageNet
          - Featured in PyTorch ecosystem tools, 4,200+ GitHub stars
        name: '[NeuralPrune](https://github.com/)'
    publications:
      - date: 2023-07
        title: 'Sparse Mixture-of-Experts at Scale: Efficient Routing for Trillion-Parameter Models'
        authors:
          - '*John Doe*'
          - Sarah Williams
          - David Park
        doi: 10.1234/neurips.2023.1234
        url:
        journal: NeurIPS 2023
      - date: 2022-12
        title: Neural Architecture Search via Differentiable Pruning
        authors:
          - James Liu
          - '*John Doe*'
        doi: 10.1234/neurips.2022.5678
        url:
        journal: NeurIPS 2022, Spotlight
      - date: 2022-07
        title: Multi-Agent Reinforcement Learning with Emergent Communication
        authors:
          - Maria Garcia
          - '*John Doe*'
          - Tom Anderson
        doi: 10.1234/icml.2022.9012
        url:
        journal: ICML 2022
      - date: 2021-05
        title: On-Device Model Compression via Learned Quantization
        authors:
          - '*John Doe*'
          - Kevin Wu
        doi: 10.1234/iclr.2021.3456
        url:
        journal: ICLR 2021, Best Paper Award
    selected_honors:
      - bullet: MIT Technology Review 35 Under 35 Innovators (2024)
      - bullet: Forbes 30 Under 30 in Enterprise Technology (2024)
      - bullet: ACM Doctoral Dissertation Award Honorable Mention (2023)
      - bullet: Google PhD Fellowship in Machine Learning (2020 – 2023)
      - bullet: Fulbright Scholarship for Graduate Studies (2018)
    skills:
      - label: Languages
        details: Python, C++, CUDA, Rust, Julia
      - label: ML Frameworks
        details: PyTorch, JAX, TensorFlow, Triton, ONNX
      - label: Infrastructure
        details: Kubernetes, Ray, distributed training, AWS, GCP
      - label: Research Areas
        details: Neural architecture search, model compression, efficient inference, multi-agent RL
    patents:
      - number: Adaptive Quantization for Neural Network Inference on Edge Devices (US Patent 11,234,567)
      - number: Dynamic Sparsity Patterns for Efficient Transformer Attention (US Patent 11,345,678)
      - number: Hardware-Aware Neural Architecture Search Method (US Patent 11,456,789)
    invited_talks:
      - reversed_number: Scaling Laws for Efficient Inference — Stanford HAI Symposium (2024)
      - reversed_number: Building AI Infrastructure for the Next Decade — TechCrunch Disrupt (2024)
      - reversed_number: 'From Research to Production: Lessons in ML Systems — NeurIPS Workshop (2023)'
      - reversed_number: "Efficient Deep Learning: A Practitioner's Perspective — Google Tech Talk (2022)"
design:
  theme: moderncv
  # page:
  #   size: us-letter
  #   top_margin: 0.7in
  #   bottom_margin: 0.7in
  #   left_margin: 0.7in
  #   right_margin: 0.7in
  #   show_footer: true
  #   show_top_note: true
  # colors:
  #   body: rgb(0, 0, 0)
  #   name: rgb(0, 79, 144)
  #   headline: rgb(0, 79, 144)
  #   connections: rgb(0, 79, 144)
  #   section_titles: rgb(0, 79, 144)
  #   links: rgb(0, 79, 144)
  #   footer: rgb(128, 128, 128)
  #   top_note: rgb(128, 128, 128)
  # typography:
  #   line_spacing: 0.6em
  #   alignment: justified
  #   date_and_location_column_alignment: right
  #   font_family:
  #     body: Fontin
  #     name: Fontin
  #     headline: Fontin
  #     connections: Fontin
  #     section_titles: Fontin
  #   font_size:
  #     body: 10pt
  #     name: 25pt
  #     headline: 10pt
  #     connections: 10pt
  #     section_titles: 1.4em
  #   small_caps:
  #     name: false
  #     headline: false
  #     connections: false
  #     section_titles: false
  #   bold:
  #     name: false
  #     headline: false
  #     connections: false
  #     section_titles: false
  # links:
  #   underline: true
  #   show_external_link_icon: false
  # header:
  #   alignment: left
  #   photo_width: 3.5cm
  #   space_below_name: 0.7cm
  #   space_below_headline: 0.7cm
  #   space_below_connections: 0.7cm
  #   connections:
  #     phone_number_format: national
  #     hyperlink: true
  #     show_icons: true
  #     display_urls_instead_of_usernames: false
  #     separator: ''
  #     space_between_connections: 0.5cm
  # section_titles:
  #   type: moderncv
  #   line_thickness: 0.15cm
  #   space_above: 0.55cm
  #   space_below: 0.3cm
  # sections:
  #   allow_page_break: true
  #   space_between_regular_entries: 1.2em
  #   space_between_text_based_entries: 0.3em
  #   show_time_spans_in: []
  # entries:
  #   date_and_location_width: 4.15cm
  #   side_space: 0cm
  #   space_between_columns: 0.3cm
  #   allow_page_break: false
  #   short_second_row: false
  #   summary:
  #     space_above: 0.1cm
  #     space_left: 0cm
  #   highlights:
  #     bullet: •
  #     nested_bullet: •
  #     space_left: 0.15cm
  #     space_above: 0.15cm
  #     space_between_items: 0.1cm
  #     space_between_bullet_and_text: 0.3em
  # templates:
  #   footer: '*NAME -- PAGE_NUMBER/TOTAL_PAGES*'
  #   top_note: '*LAST_UPDATED CURRENT_DATE*'
  #   single_date: MONTH_ABBREVIATION YEAR
  #   date_range: START_DATE – END_DATE
  #   time_span: HOW_MANY_YEARS YEARS HOW_MANY_MONTHS MONTHS
  #   one_line_entry:
  #     main_column: '**LABEL:** DETAILS'
  #   education_entry:
  #     main_column: |-
  #       **INSTITUTION**, DEGREE in AREA -- LOCATION
  #       SUMMARY
  #       HIGHLIGHTS
  #     degree_column:
  #     date_and_location_column: DATE
  #   normal_entry:
  #     main_column: |-
  #       **NAME** -- **LOCATION**
  #       SUMMARY
  #       HIGHLIGHTS
  #     date_and_location_column: DATE
  #   experience_entry:
  #     main_column: |-
  #       **POSITION**, COMPANY -- LOCATION
  #       SUMMARY
  #       HIGHLIGHTS
  #     date_and_location_column: DATE
  #   publication_entry:
  #     main_column: |-
  #       **TITLE**
  #       AUTHORS
  #       URL (JOURNAL)
  #     date_and_location_column: DATE
locale:
  language: english
  last_updated: Last updated in
  month: month
  months: months
  year: year
  years: years
  present: present
  month_abbreviations:
    - Jan
    - Feb
    - Mar
    - Apr
    - May
    - June
    - July
    - Aug
    - Sept
    - Oct
    - Nov
    - Dec
  month_names:
    - January
    - February
    - March
    - April
    - May
    - June
    - July
    - August
    - September
    - October
    - November
    - December
settings:
  current_date: '2025-11-29'
  bold_keywords: []
